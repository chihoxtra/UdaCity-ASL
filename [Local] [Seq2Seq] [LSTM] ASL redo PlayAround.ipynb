{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import os\n",
    "from asl_data import AslDb\n",
    "from asl_utils import show_errors\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_accuracy(md, X, Y):\n",
    "    \"\"\"\n",
    "    Using the model to make prediction with accuracy as return\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = np.argmax(md.predict(X), axis=1)\n",
    "    truth = np.argmax(Y, axis=1)\n",
    "    accuracy = np.mean(pred == truth)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveDataFeatures():\n",
    "    \n",
    "    asl = AslDb()\n",
    "    \n",
    "    # calculate the coordinates of hands w.r.t the coordinates of nose \n",
    "    asl.df['grnd-ry'] = asl.df['right-y'] - asl.df['nose-y']\n",
    "    asl.df['grnd-rx'] = asl.df['right-x'] - asl.df['nose-x']\n",
    "    asl.df['grnd-ly'] = asl.df['left-y'] - asl.df['nose-y']\n",
    "    asl.df['grnd-lx'] = asl.df['left-x'] - asl.df['nose-x']\n",
    "\n",
    "    # save relative coordinates as features\n",
    "    features_ground = ['grnd-rx','grnd-ry','grnd-lx','grnd-ly']\n",
    "\n",
    "    # calculate the polar coordinates from Cartesian coordinates\n",
    "    asl.df['polar-lr'] = np.sqrt(np.square(asl.df['grnd-ly']) + np.square(asl.df['grnd-lx']))\n",
    "    asl.df['polar-ltheta'] = np.arctan2(asl.df['grnd-lx'], asl.df['grnd-ly'])\n",
    "    asl.df['polar-rr'] = np.sqrt(np.square(asl.df['grnd-ry']) + np.square(asl.df['grnd-rx']))\n",
    "    asl.df['polar-rtheta'] = np.arctan2(asl.df['grnd-rx'], asl.df['grnd-ry'])\n",
    "\n",
    "    features_polar = ['polar-rr', 'polar-rtheta','polar-lr', 'polar-ltheta']\n",
    "\n",
    "    train_rawdata = asl.build_data(features_polar, csvfile=os.path.join('data', 'train_words.csv'))  \n",
    "    test_rawdata = asl.build_data(features_polar, csvfile=os.path.join('data', 'test_words.csv'))  \n",
    "    \n",
    "    return train_rawdata, test_rawdata, asl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part I Extract Features from data\n",
    "train_dataset, test_dataset, asl = retrieveDataFeatures() #asl.df is a pandas dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVocabDict(completeWordsList):\n",
    "    \"\"\"\n",
    "        completeWordsList: LIST format of unique wrords including special characters needed to create\n",
    "        special_words = ['<SOS>','<EOS>','<UKN>'] for training by sentence (LM)\n",
    "        \n",
    "        return:\n",
    "        vocabList: a list of unique vocab including special characters\n",
    "        index2vocab: dict: index: vocab look up\n",
    "        vocab2index: dict: vocab: index look up\n",
    "    \"\"\"\n",
    "    # making sure '<PAD>' if of position index 0\n",
    "    completeWordsList = list(reversed(completeWordsList))\n",
    "    \n",
    "    index2vocab = {indx:vals for indx, vals in enumerate(completeWordsList)}\n",
    "    vocab2index = {vals: indx for indx, vals in index2vocab.items()}\n",
    "        \n",
    "    return list(completeWordsList), index2vocab, vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710\n",
      "178\n",
      "66\n",
      "Total number of words in master list: 116\n"
     ]
    }
   ],
   "source": [
    "# create Master Words Dictionary and related index/vocab look up dict\n",
    "print(len(train_dataset.wordlist)) #note that this is NOT a unique dictionary\n",
    "print(len(test_dataset.wordlist)) #note that this is NOT a unique dictionary\n",
    "print(len(set(test_dataset.wordlist))) #note that this is NOT a unique dictionary\n",
    "\n",
    "completeWordsList = set(test_dataset.wordlist).union(set(train_dataset.wordlist))\n",
    "masterWordList, index2vocab, vocab2index = createVocabDict(list(completeWordsList)+['<SOS>','<EOS>','<PAD>'])\n",
    "\n",
    "print(\"Total number of words in master list: {}\".format(len(masterWordList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '<PAD>')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2index['<PAD>'], index2vocab[0], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(dataset, vocabList, training_mode=\"byWord\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    parameters: \n",
    "        dataset: SingleData object\n",
    "        training_mode: \"byWord\" -> a sequence of frame to softmax words classification\n",
    "                       (number of words, max no of frames per word, no features per frame)\n",
    "                       \"bySentence\" -> a sequence of frame to softmax sequence of words (Language Model)\n",
    "                       (number of sentence, max no of word per sent * max no of frames per word, no features per frame)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Prepare Word Dictionary for one hot\n",
    "    maxFramesPerWord = 100 #max no of frames (4 features per frame) allowed for each word\n",
    "    maxWordPerSentence = 10 #max no of words per sentence\n",
    "    featuresPerFrame = 4 #no of features per frame    \n",
    "    noOfClasses = len(vocabList) #no of classes for words classification\n",
    "    \n",
    "    if training_mode==\"byWord\":\n",
    "        \n",
    "        noOfClasses = len(vocabList) #no of classes for words classification\n",
    "        \n",
    "        # initialize zeros arrays for X_train and Y_train\n",
    "        m = dataset.num_items # Use word level training (ie not using language model) ie 710\n",
    "\n",
    "        X_array = np.zeros([m,maxFramesPerWord,featuresPerFrame])\n",
    "        Y_array = np.zeros([m,noOfClasses], dtype=np.int32)\n",
    "\n",
    "        # fill in the sequence values\n",
    "        all_sequences = dataset.get_all_sequences()\n",
    "\n",
    "        for keys, values in all_sequences.items():\n",
    "            X_array[keys,:len(all_sequences[keys][0]),:] = np.array(all_sequences[keys])\n",
    "            Y_array[keys,:] = (dataset.wordlist[keys] == np.array(vocabList))*1\n",
    "    else:\n",
    "        \n",
    "        # initialize zeros arrays for X_train and Y_train\n",
    "        m = dataset.num_sentences # Use SENTENCE level training ie 161\n",
    "\n",
    "        Tx = maxWordPerSentence*maxFramesPerWord\n",
    "        Ty = maxWordPerSentence\n",
    "\n",
    "        X_array = np.zeros([m,Tx,featuresPerFrame])\n",
    "        Y_array = np.zeros([m,Ty,noOfClasses], dtype=np.int32)\n",
    "        Y_array = Y_array + vocab2index['<PAD>'] # change the padding values\n",
    "\n",
    "        # fill in the sequence values\n",
    "        sentence_count = 0\n",
    "        for keys, values in dataset.sentences_index.items():\n",
    "            word_index_seq = values\n",
    "\n",
    "            next_ind = 0\n",
    "            word_count = 0\n",
    "            for wi in word_index_seq:\n",
    "                this_seq = dataset.get_item_sequences(wi)[0]\n",
    "\n",
    "                X_array[sentence_count,next_ind:next_ind+len(this_seq),:] = this_seq\n",
    "                #print(next_ind, len(this_seq))\n",
    "                next_ind =  next_ind + len(this_seq)\n",
    "\n",
    "                Y_array[sentence_count,word_count+1,:] = (dataset.wordlist[wi] == np.array(vocabList))*1\n",
    "                word_count+=1\n",
    "            Y_array[sentence_count,0,:] = ('<SOS>' == np.array(vocabList))*1\n",
    "            Y_array[sentence_count,word_count+1,:] = ('<EOS>' == np.array(vocabList))*1\n",
    "\n",
    "            sentence_count += 1\n",
    "    \n",
    "    print(\"Shape of X_array: {}\".format(X_array.shape))\n",
    "    print(\"Shape of Y_array: {}\".format(Y_array.shape))\n",
    "    print(\"Total number of UNIQUE words from data set: {}\".format(len(vocabList)))\n",
    "    \n",
    "    return X_array, Y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDecoderTarget(decoder_input):\n",
    "    \"\"\"Create the decoder target by rolling the decoder_input\"\"\"\n",
    "    \n",
    "    decoder_target = np.roll(decoder_input, -1, axis=1)\n",
    "    decoder_target[:,-1,:] = 0\n",
    "    assert(np.sum(decoder_target[:,0,:] - decoder_input[:,1,:]) == 0)\n",
    "    assert(decoder_target.shape == decoder_input.shape)\n",
    "    \n",
    "    return decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showWER(ds, m, m_input):\n",
    "    \n",
    "    sentence_count = 0\n",
    "    guessList = []\n",
    "    \n",
    "    #do an index mapping between the sorted dict used in original code and the unsorted one used in my code\n",
    "    sorted_index = [s[0] for s in sorted(ds.sentences_index.items())]\n",
    "    original_index = [s[0] for s in ds.sentences_index.items()]\n",
    "\n",
    "    pred_index = np.argmax(m.predict(m_input), axis=-1)\n",
    "    \n",
    "    for keys, values in sorted(ds.sentences_index.items()):\n",
    "\n",
    "        truth = [ds.wordlist[w] for w in values]\n",
    "\n",
    "        convert_index = original_index.index(sorted_index[sentence_count])\n",
    "        pred_out = [index2vocab[t] for t in pred_index[convert_index,:]][:len(values)]\n",
    "\n",
    "        guessList.extend(pred_out)\n",
    "        sentence_count += 1 \n",
    "    \n",
    "    show_errors(guessList, ds, show_answer = True)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training by Sentence ###\n",
    "This time around we will be using a language model. Instead of recognizing chose frame features word by word, we will be recognizing the whole sentence by taking into considerations of probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_array: (161, 1000, 4)\n",
      "Shape of Y_array: (161, 10, 116)\n",
      "Total number of UNIQUE words from data set: 116\n"
     ]
    }
   ],
   "source": [
    "#Part II Prepare Training data\n",
    "train_encoder_input, train_decoder_input = prepareData(train_dataset, masterWordList, training_mode=\"bySentence\")\n",
    "train_decoder_target = prepareDecoderTarget(train_decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_array: (40, 1000, 4)\n",
      "Shape of Y_array: (40, 10, 116)\n",
      "Total number of UNIQUE words from data set: 116\n"
     ]
    }
   ],
   "source": [
    "#Part II Prepare Test data\n",
    "test_encoder_input, test_decoder_input = prepareData(test_dataset, masterWordList, training_mode=\"bySentence\")\n",
    "test_decoder_target = prepareDecoderTarget(test_decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqIndex2Sentence(seq, i):\n",
    "    sentence = ''\n",
    "    for t in range(train_decoder_input.shape[1]):\n",
    "        sentence = sentence + index2vocab[np.argmax(seq[i,t,:])] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOHN CAN GO1 CAN <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqIndex2Sentence(train_decoder_target, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Part III prepare the model\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape, Concatenate, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, Tx, noOfFeatures = train_encoder_input.shape\n",
    "_, Ty, noOfClasses = train_decoder_input.shape\n",
    "latent_dim = 64\n",
    "model_filepath = 'models/model_seq2seq_lm9Oct2018.h5'\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENCODER ###\n",
    "encoder_inputs = Input(shape=(None, noOfFeatures), name='encoder_inputs')\n",
    "encoder = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# Output is disregarded; these states will be used as the initial stated for the decoder\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# define the encoder model separately\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "### DECODER ###\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, noOfClasses), name='decoder_inputs')\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, \n",
    "                    return_state=True, name='decoder_lstm')\n",
    "\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, \n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(noOfClasses, activation='softmax', name='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, None, 116)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 64), (None,  17664       encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 64), ( 46336       decoder_inputs[0][0]             \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, None, 116)    7540        decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 71,540\n",
      "Trainable params: 71,540\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer=keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=1e-7)\n",
    "optimizer=keras.optimizers.RMSprop(lr=0.00005, rho=0.9, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "checkpoint = ModelCheckpoint(model_filepath, monitor='loss', verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model(model_filepath)\n",
    "model.load_weights('models/model_seq2seq_lm_weights9Oct2018.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161 samples, validate on 40 samples\n",
      "Epoch 1/100\n",
      "Epoch 00001: loss improved from 0.30846 to 0.30806, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 6s - loss: 0.3081 - acc: 0.4540 - val_loss: 0.8146 - val_acc: 0.3850\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelpun_old/anaconda/envs/tensorflow/lib/python3.5/site-packages/keras/engine/topology.py:2344: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoder_lstm_4/while/Exit_2:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'encoder_lstm_4/while/Exit_3:0' shape=(?, 64) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00002: loss did not improve\n",
      " - 6s - loss: 0.3107 - acc: 0.4509 - val_loss: 0.8248 - val_acc: 0.3875\n",
      "Epoch 3/100\n",
      "Epoch 00003: loss did not improve\n",
      " - 6s - loss: 0.3085 - acc: 0.4516 - val_loss: 0.8294 - val_acc: 0.3875\n",
      "Epoch 4/100\n",
      "Epoch 00004: loss did not improve\n",
      " - 6s - loss: 0.3094 - acc: 0.4522 - val_loss: 0.8212 - val_acc: 0.3875\n",
      "Epoch 5/100\n",
      "Epoch 00005: loss improved from 0.30806 to 0.30785, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 6s - loss: 0.3079 - acc: 0.4528 - val_loss: 0.8248 - val_acc: 0.3850\n",
      "Epoch 6/100\n",
      "Epoch 00006: loss did not improve\n",
      " - 6s - loss: 0.3125 - acc: 0.4522 - val_loss: 0.8209 - val_acc: 0.3875\n",
      "Epoch 7/100\n",
      "Epoch 00007: loss did not improve\n",
      " - 6s - loss: 0.3110 - acc: 0.4522 - val_loss: 0.8156 - val_acc: 0.3875\n",
      "Epoch 8/100\n",
      "Epoch 00008: loss did not improve\n",
      " - 6s - loss: 0.3084 - acc: 0.4528 - val_loss: 0.8170 - val_acc: 0.3875\n",
      "Epoch 9/100\n",
      "Epoch 00009: loss did not improve\n",
      " - 6s - loss: 0.3093 - acc: 0.4522 - val_loss: 0.8207 - val_acc: 0.3850\n",
      "Epoch 10/100\n",
      "Epoch 00010: loss did not improve\n",
      " - 6s - loss: 0.3107 - acc: 0.4491 - val_loss: 0.8149 - val_acc: 0.3875\n",
      "Epoch 11/100\n",
      "Epoch 00011: loss did not improve\n",
      " - 7s - loss: 0.3087 - acc: 0.4547 - val_loss: 0.8225 - val_acc: 0.3875\n",
      "Epoch 12/100\n",
      "Epoch 00012: loss did not improve\n",
      " - 7s - loss: 0.3080 - acc: 0.4528 - val_loss: 0.8233 - val_acc: 0.3875\n",
      "Epoch 13/100\n",
      "Epoch 00013: loss did not improve\n",
      " - 7s - loss: 0.3091 - acc: 0.4516 - val_loss: 0.8245 - val_acc: 0.3900\n",
      "Epoch 14/100\n",
      "Epoch 00014: loss did not improve\n",
      " - 6s - loss: 0.3112 - acc: 0.4516 - val_loss: 0.8154 - val_acc: 0.3875\n",
      "Epoch 15/100\n",
      "Epoch 00015: loss did not improve\n",
      " - 6s - loss: 0.3090 - acc: 0.4528 - val_loss: 0.8296 - val_acc: 0.3850\n",
      "Epoch 16/100\n",
      "Epoch 00016: loss did not improve\n",
      " - 5s - loss: 0.3090 - acc: 0.4522 - val_loss: 0.8175 - val_acc: 0.3900\n",
      "Epoch 17/100\n",
      "Epoch 00017: loss did not improve\n",
      " - 6s - loss: 0.3084 - acc: 0.4528 - val_loss: 0.8196 - val_acc: 0.3850\n",
      "Epoch 18/100\n",
      "Epoch 00018: loss did not improve\n",
      " - 6s - loss: 0.3082 - acc: 0.4547 - val_loss: 0.8174 - val_acc: 0.3900\n",
      "Epoch 19/100\n",
      "Epoch 00019: loss did not improve\n",
      " - 7s - loss: 0.3090 - acc: 0.4534 - val_loss: 0.8148 - val_acc: 0.3825\n",
      "Epoch 20/100\n",
      "Epoch 00020: loss did not improve\n",
      " - 6s - loss: 0.3106 - acc: 0.4522 - val_loss: 0.8159 - val_acc: 0.3850\n",
      "Epoch 21/100\n",
      "Epoch 00021: loss did not improve\n",
      " - 6s - loss: 0.3104 - acc: 0.4534 - val_loss: 0.8247 - val_acc: 0.3875\n",
      "Epoch 22/100\n",
      "Epoch 00022: loss did not improve\n",
      " - 6s - loss: 0.3087 - acc: 0.4522 - val_loss: 0.8205 - val_acc: 0.3875\n",
      "Epoch 23/100\n",
      "Epoch 00023: loss improved from 0.30785 to 0.30767, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 5s - loss: 0.3077 - acc: 0.4534 - val_loss: 0.8167 - val_acc: 0.3900\n",
      "Epoch 24/100\n",
      "Epoch 00024: loss improved from 0.30767 to 0.30757, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 6s - loss: 0.3076 - acc: 0.4534 - val_loss: 0.8210 - val_acc: 0.3900\n",
      "Epoch 25/100\n",
      "Epoch 00025: loss did not improve\n",
      " - 6s - loss: 0.3084 - acc: 0.4547 - val_loss: 0.8188 - val_acc: 0.3875\n",
      "Epoch 26/100\n",
      "Epoch 00026: loss improved from 0.30757 to 0.30730, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 8s - loss: 0.3073 - acc: 0.4553 - val_loss: 0.8180 - val_acc: 0.3900\n",
      "Epoch 27/100\n",
      "Epoch 00027: loss did not improve\n",
      " - 6s - loss: 0.3086 - acc: 0.4528 - val_loss: 0.8240 - val_acc: 0.3900\n",
      "Epoch 28/100\n",
      "Epoch 00028: loss did not improve\n",
      " - 6s - loss: 0.3095 - acc: 0.4528 - val_loss: 0.8294 - val_acc: 0.3850\n",
      "Epoch 29/100\n",
      "Epoch 00029: loss did not improve\n",
      " - 6s - loss: 0.3103 - acc: 0.4528 - val_loss: 0.8299 - val_acc: 0.3825\n",
      "Epoch 30/100\n",
      "Epoch 00030: loss did not improve\n",
      " - 6s - loss: 0.3086 - acc: 0.4528 - val_loss: 0.8265 - val_acc: 0.3875\n",
      "Epoch 31/100\n",
      "Epoch 00031: loss improved from 0.30730 to 0.30703, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 6s - loss: 0.3070 - acc: 0.4547 - val_loss: 0.8215 - val_acc: 0.3850\n",
      "Epoch 32/100\n",
      "Epoch 00032: loss did not improve\n",
      " - 6s - loss: 0.3101 - acc: 0.4522 - val_loss: 0.8277 - val_acc: 0.3850\n",
      "Epoch 33/100\n",
      "Epoch 00033: loss improved from 0.30703 to 0.30697, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 6s - loss: 0.3070 - acc: 0.4540 - val_loss: 0.8282 - val_acc: 0.3825\n",
      "Epoch 34/100\n",
      "Epoch 00034: loss did not improve\n",
      " - 7s - loss: 0.3084 - acc: 0.4540 - val_loss: 0.8245 - val_acc: 0.3875\n",
      "Epoch 35/100\n",
      "Epoch 00035: loss did not improve\n",
      " - 6s - loss: 0.3093 - acc: 0.4522 - val_loss: 0.8193 - val_acc: 0.3875\n",
      "Epoch 36/100\n",
      "Epoch 00036: loss did not improve\n",
      " - 6s - loss: 0.3085 - acc: 0.4503 - val_loss: 0.8232 - val_acc: 0.3825\n",
      "Epoch 37/100\n",
      "Epoch 00037: loss did not improve\n",
      " - 6s - loss: 0.3081 - acc: 0.4522 - val_loss: 0.8269 - val_acc: 0.3875\n",
      "Epoch 38/100\n",
      "Epoch 00038: loss did not improve\n",
      " - 9s - loss: 0.3088 - acc: 0.4540 - val_loss: 0.8191 - val_acc: 0.3850\n",
      "Epoch 39/100\n",
      "Epoch 00039: loss did not improve\n",
      " - 8s - loss: 0.3080 - acc: 0.4528 - val_loss: 0.8225 - val_acc: 0.3825\n",
      "Epoch 40/100\n",
      "Epoch 00040: loss did not improve\n",
      " - 7s - loss: 0.3081 - acc: 0.4522 - val_loss: 0.8239 - val_acc: 0.3875\n",
      "Epoch 41/100\n",
      "Epoch 00041: loss did not improve\n",
      " - 7s - loss: 0.3071 - acc: 0.4540 - val_loss: 0.8201 - val_acc: 0.3850\n",
      "Epoch 42/100\n",
      "Epoch 00042: loss did not improve\n",
      " - 6s - loss: 0.3091 - acc: 0.4534 - val_loss: 0.8172 - val_acc: 0.3875\n",
      "Epoch 43/100\n",
      "Epoch 00043: loss did not improve\n",
      " - 6s - loss: 0.3092 - acc: 0.4522 - val_loss: 0.8261 - val_acc: 0.3850\n",
      "Epoch 44/100\n",
      "Epoch 00044: loss did not improve\n",
      " - 7s - loss: 0.3088 - acc: 0.4547 - val_loss: 0.8092 - val_acc: 0.3875\n",
      "Epoch 45/100\n",
      "Epoch 00045: loss did not improve\n",
      " - 8s - loss: 0.3073 - acc: 0.4553 - val_loss: 0.8205 - val_acc: 0.3850\n",
      "Epoch 46/100\n",
      "Epoch 00046: loss did not improve\n",
      " - 6s - loss: 0.3079 - acc: 0.4540 - val_loss: 0.8159 - val_acc: 0.3900\n",
      "Epoch 47/100\n",
      "Epoch 00047: loss improved from 0.30697 to 0.30695, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 6s - loss: 0.3069 - acc: 0.4540 - val_loss: 0.8118 - val_acc: 0.3900\n",
      "Epoch 48/100\n",
      "Epoch 00048: loss improved from 0.30695 to 0.30662, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 6s - loss: 0.3066 - acc: 0.4528 - val_loss: 0.8118 - val_acc: 0.3875\n",
      "Epoch 49/100\n",
      "Epoch 00049: loss did not improve\n",
      " - 6s - loss: 0.3077 - acc: 0.4547 - val_loss: 0.8161 - val_acc: 0.3875\n",
      "Epoch 50/100\n",
      "Epoch 00050: loss did not improve\n",
      " - 6s - loss: 0.3067 - acc: 0.4522 - val_loss: 0.8161 - val_acc: 0.3875\n",
      "Epoch 51/100\n",
      "Epoch 00051: loss did not improve\n",
      " - 6s - loss: 0.3071 - acc: 0.4516 - val_loss: 0.8178 - val_acc: 0.3900\n",
      "Epoch 52/100\n",
      "Epoch 00052: loss improved from 0.30662 to 0.30576, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 6s - loss: 0.3058 - acc: 0.4534 - val_loss: 0.8260 - val_acc: 0.3850\n",
      "Epoch 53/100\n",
      "Epoch 00053: loss did not improve\n",
      " - 6s - loss: 0.3067 - acc: 0.4522 - val_loss: 0.8306 - val_acc: 0.3850\n",
      "Epoch 54/100\n",
      "Epoch 00054: loss did not improve\n",
      " - 6s - loss: 0.3103 - acc: 0.4522 - val_loss: 0.8202 - val_acc: 0.3850\n",
      "Epoch 55/100\n",
      "Epoch 00055: loss did not improve\n",
      " - 6s - loss: 0.3083 - acc: 0.4516 - val_loss: 0.8199 - val_acc: 0.3850\n",
      "Epoch 56/100\n",
      "Epoch 00056: loss did not improve\n",
      " - 7s - loss: 0.3075 - acc: 0.4540 - val_loss: 0.8212 - val_acc: 0.3850\n",
      "Epoch 57/100\n",
      "Epoch 00057: loss did not improve\n",
      " - 7s - loss: 0.3065 - acc: 0.4534 - val_loss: 0.8184 - val_acc: 0.3850\n",
      "Epoch 58/100\n",
      "Epoch 00058: loss did not improve\n",
      " - 7s - loss: 0.3064 - acc: 0.4528 - val_loss: 0.8192 - val_acc: 0.3875\n",
      "Epoch 59/100\n",
      "Epoch 00059: loss did not improve\n",
      " - 7s - loss: 0.3059 - acc: 0.4540 - val_loss: 0.8186 - val_acc: 0.3850\n",
      "Epoch 60/100\n",
      "Epoch 00060: loss did not improve\n",
      " - 7s - loss: 0.3063 - acc: 0.4528 - val_loss: 0.8209 - val_acc: 0.3825\n",
      "Epoch 61/100\n",
      "Epoch 00061: loss did not improve\n",
      " - 6s - loss: 0.3077 - acc: 0.4522 - val_loss: 0.8165 - val_acc: 0.3875\n",
      "Epoch 62/100\n",
      "Epoch 00062: loss improved from 0.30576 to 0.30556, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 6s - loss: 0.3056 - acc: 0.4528 - val_loss: 0.8243 - val_acc: 0.3850\n",
      "Epoch 63/100\n",
      "Epoch 00063: loss did not improve\n",
      " - 6s - loss: 0.3079 - acc: 0.4522 - val_loss: 0.8273 - val_acc: 0.3875\n",
      "Epoch 64/100\n",
      "Epoch 00064: loss did not improve\n",
      " - 5s - loss: 0.3104 - acc: 0.4516 - val_loss: 0.8198 - val_acc: 0.3825\n",
      "Epoch 65/100\n",
      "Epoch 00065: loss did not improve\n",
      " - 7s - loss: 0.3081 - acc: 0.4528 - val_loss: 0.8216 - val_acc: 0.3850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "Epoch 00066: loss did not improve\n",
      " - 6s - loss: 0.3056 - acc: 0.4540 - val_loss: 0.8231 - val_acc: 0.3850\n",
      "Epoch 67/100\n",
      "Epoch 00067: loss did not improve\n",
      " - 7s - loss: 0.3056 - acc: 0.4540 - val_loss: 0.8224 - val_acc: 0.3875\n",
      "Epoch 68/100\n",
      "Epoch 00068: loss did not improve\n",
      " - 7s - loss: 0.3061 - acc: 0.4528 - val_loss: 0.8212 - val_acc: 0.3875\n",
      "Epoch 69/100\n",
      "Epoch 00069: loss did not improve\n",
      " - 7s - loss: 0.3070 - acc: 0.4540 - val_loss: 0.8221 - val_acc: 0.3850\n",
      "Epoch 70/100\n",
      "Epoch 00070: loss did not improve\n",
      " - 7s - loss: 0.3060 - acc: 0.4534 - val_loss: 0.8176 - val_acc: 0.3900\n",
      "Epoch 71/100\n",
      "Epoch 00071: loss did not improve\n",
      " - 6s - loss: 0.3064 - acc: 0.4547 - val_loss: 0.8180 - val_acc: 0.3900\n",
      "Epoch 72/100\n",
      "Epoch 00072: loss did not improve\n",
      " - 6s - loss: 0.3112 - acc: 0.4503 - val_loss: 0.8160 - val_acc: 0.3875\n",
      "Epoch 73/100\n",
      "Epoch 00073: loss did not improve\n",
      " - 6s - loss: 0.3075 - acc: 0.4516 - val_loss: 0.8094 - val_acc: 0.3925\n",
      "Epoch 74/100\n",
      "Epoch 00074: loss did not improve\n",
      " - 6s - loss: 0.3079 - acc: 0.4528 - val_loss: 0.8181 - val_acc: 0.3875\n",
      "Epoch 75/100\n",
      "Epoch 00075: loss did not improve\n",
      " - 6s - loss: 0.3063 - acc: 0.4509 - val_loss: 0.8198 - val_acc: 0.3875\n",
      "Epoch 76/100\n",
      "Epoch 00076: loss did not improve\n",
      " - 6s - loss: 0.3064 - acc: 0.4534 - val_loss: 0.8180 - val_acc: 0.3875\n",
      "Epoch 77/100\n",
      "Epoch 00077: loss improved from 0.30556 to 0.30478, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 6s - loss: 0.3048 - acc: 0.4547 - val_loss: 0.8288 - val_acc: 0.3875\n",
      "Epoch 78/100\n",
      "Epoch 00078: loss did not improve\n",
      " - 5s - loss: 0.3073 - acc: 0.4528 - val_loss: 0.8161 - val_acc: 0.3900\n",
      "Epoch 79/100\n",
      "Epoch 00079: loss did not improve\n",
      " - 6s - loss: 0.3064 - acc: 0.4540 - val_loss: 0.8186 - val_acc: 0.3875\n",
      "Epoch 80/100\n",
      "Epoch 00080: loss did not improve\n",
      " - 6s - loss: 0.3062 - acc: 0.4553 - val_loss: 0.8187 - val_acc: 0.3900\n",
      "Epoch 81/100\n",
      "Epoch 00081: loss did not improve\n",
      " - 6s - loss: 0.3059 - acc: 0.4540 - val_loss: 0.8147 - val_acc: 0.3850\n",
      "Epoch 82/100\n",
      "Epoch 00082: loss did not improve\n",
      " - 6s - loss: 0.3055 - acc: 0.4534 - val_loss: 0.8191 - val_acc: 0.3875\n",
      "Epoch 83/100\n",
      "Epoch 00083: loss did not improve\n",
      " - 7s - loss: 0.3058 - acc: 0.4534 - val_loss: 0.8185 - val_acc: 0.3850\n",
      "Epoch 84/100\n",
      "Epoch 00084: loss did not improve\n",
      " - 5s - loss: 0.3087 - acc: 0.4497 - val_loss: 0.8176 - val_acc: 0.3850\n",
      "Epoch 85/100\n",
      "Epoch 00085: loss did not improve\n",
      " - 6s - loss: 0.3056 - acc: 0.4534 - val_loss: 0.8121 - val_acc: 0.3900\n",
      "Epoch 86/100\n",
      "Epoch 00086: loss did not improve\n",
      " - 6s - loss: 0.3048 - acc: 0.4540 - val_loss: 0.8186 - val_acc: 0.3900\n",
      "Epoch 87/100\n",
      "Epoch 00087: loss did not improve\n",
      " - 6s - loss: 0.3050 - acc: 0.4534 - val_loss: 0.8160 - val_acc: 0.3900\n",
      "Epoch 88/100\n",
      "Epoch 00088: loss improved from 0.30478 to 0.30436, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 7s - loss: 0.3044 - acc: 0.4540 - val_loss: 0.8212 - val_acc: 0.3800\n",
      "Epoch 89/100\n",
      "Epoch 00089: loss did not improve\n",
      " - 6s - loss: 0.3074 - acc: 0.4528 - val_loss: 0.8222 - val_acc: 0.3875\n",
      "Epoch 90/100\n",
      "Epoch 00090: loss did not improve\n",
      " - 6s - loss: 0.3082 - acc: 0.4522 - val_loss: 0.8298 - val_acc: 0.3900\n",
      "Epoch 91/100\n",
      "Epoch 00091: loss did not improve\n",
      " - 6s - loss: 0.3077 - acc: 0.4534 - val_loss: 0.8184 - val_acc: 0.3875\n",
      "Epoch 92/100\n",
      "Epoch 00092: loss did not improve\n",
      " - 6s - loss: 0.3061 - acc: 0.4540 - val_loss: 0.8232 - val_acc: 0.3875\n",
      "Epoch 93/100\n",
      "Epoch 00093: loss did not improve\n",
      " - 6s - loss: 0.3051 - acc: 0.4540 - val_loss: 0.8235 - val_acc: 0.3875\n",
      "Epoch 94/100\n",
      "Epoch 00094: loss did not improve\n",
      " - 7s - loss: 0.3063 - acc: 0.4528 - val_loss: 0.8243 - val_acc: 0.3850\n",
      "Epoch 95/100\n",
      "Epoch 00095: loss did not improve\n",
      " - 6s - loss: 0.3046 - acc: 0.4547 - val_loss: 0.8229 - val_acc: 0.3875\n",
      "Epoch 96/100\n",
      "Epoch 00096: loss improved from 0.30436 to 0.30426, saving model to models/model_seq2seq_lm9Oct2018.h5\n",
      " - 7s - loss: 0.3043 - acc: 0.4534 - val_loss: 0.8237 - val_acc: 0.3875\n",
      "Epoch 97/100\n",
      "Epoch 00097: loss did not improve\n",
      " - 6s - loss: 0.3066 - acc: 0.4528 - val_loss: 0.8232 - val_acc: 0.3850\n",
      "Epoch 98/100\n",
      "Epoch 00098: loss did not improve\n",
      " - 6s - loss: 0.3053 - acc: 0.4522 - val_loss: 0.8238 - val_acc: 0.3900\n",
      "Epoch 99/100\n",
      "Epoch 00099: loss did not improve\n",
      " - 6s - loss: 0.3055 - acc: 0.4534 - val_loss: 0.8236 - val_acc: 0.3875\n",
      "Epoch 100/100\n",
      "Epoch 00100: loss did not improve\n",
      " - 5s - loss: 0.3097 - acc: 0.4522 - val_loss: 0.8236 - val_acc: 0.3925\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit([train_encoder_input, train_decoder_input], train_decoder_target,\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 callbacks=callbacks_list,\n",
    "                 validation_data=[[test_encoder_input, test_decoder_input], test_decoder_target],\n",
    "                 #validation_split=0.15,\n",
    "                 verbose=2\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/model_seq2seq_lm_weights9Oct2018.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 50.97451274362819%\n",
      "Test accuracy: 47.11206896551724%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: {}%\".format(pred_accuracy(model, [train_encoder_input, train_decoder_input], \n",
    "                                                    train_decoder_target)*100.))\n",
    "print(\"Test accuracy: {}%\".format(pred_accuracy(model, [test_encoder_input, test_decoder_input],  \n",
    "                                                test_decoder_target)*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JOHN', 'SHOULD', 'NOT', 'BUY', 'HOUSE', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "['JOHN', 'FUTURE', 'NOT', 'BUY', 'HOUSE', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.argmax(model.predict([test_encoder_input, test_decoder_input]), axis=-1) \n",
    "test_truth = np.argmax(test_decoder_target, axis=-1)\n",
    "\n",
    "print(([index2vocab[t] for t in test_pred[2,:]]))\n",
    "print([index2vocab[t] for t in test_truth[2,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** WER = 0.34269662921348315\n",
      "\n",
      "Total correct: 117 out of 178\n",
      "Video  Recognized                                                    Correct\n",
      "=====================================================================================================\n",
      "  100: *JOHN NEW CAR BREAK-DOWN                                      POSS NEW CAR BREAK-DOWN\n",
      "    2: JOHN *SHOULD HOMEWORK                                         JOHN WRITE HOMEWORK\n",
      "   67: JOHN *SHOULD NOT BUY HOUSE                                    JOHN FUTURE NOT BUY HOUSE\n",
      "    7: JOHN CAN *BUY CAN                                             JOHN CAN GO CAN\n",
      "  201: JOHN *SHOULD *VISIT *<EOS> BUY HOUSE                          JOHN TELL MARY IX-1P BUY HOUSE\n",
      "   74: JOHN *IX VISIT MARY                                           JOHN NOT VISIT MARY\n",
      "  119: *JOHN *BUY1 *CAR CAR BLUE                                     SUE BUY IX CAR BLUE\n",
      "   12: JOHN CAN *GO1 CAN                                             JOHN CAN GO CAN\n",
      "   77: *JOHN BLAME MARY                                              ANN BLAME MARY\n",
      "  142: JOHN BUY *WHAT WHAT BOOK                                      JOHN BUY YESTERDAY WHAT BOOK\n",
      "  107: JOHN *LEAVE *LEG HAVE CANDY                                   JOHN POSS FRIEND HAVE CANDY\n",
      "   84: *JOHN FIND SOMETHING-ONE *POSS                                IX-1P FIND SOMETHING-ONE BOOK\n",
      "   21: JOHN *FUTURE WONT EAT BUT CAN EAT CHICKEN                     JOHN FISH WONT EAT BUT CAN EAT CHICKEN\n",
      "   25: JOHN LIKE IX IX IX                                            JOHN LIKE IX IX IX\n",
      "   89: JOHN *SEE GIVE *IX IX NEW COAT                                JOHN IX GIVE MAN IX NEW COAT\n",
      "   71: JOHN *LEAVE VISIT MARY                                        JOHN WILL VISIT MARY\n",
      "   92: JOHN *GIVE1 *GIRL *GIVE WOMAN BOOK                            JOHN GIVE IX SOMETHING-ONE WOMAN BOOK\n",
      "   90: JOHN *GIVE1 *GIRL *GIVE WOMAN BOOK                            JOHN GIVE IX SOMETHING-ONE WOMAN BOOK\n",
      "   30: JOHN LIKE IX IX IX                                            JOHN LIKE IX IX IX\n",
      "  193: JOHN *LIKE *IX BOX                                            JOHN GIVE GIRL BOX\n",
      "   36: *JOHN *BILL KNOW IX LIKE CORN1                                MARY VEGETABLE KNOW IX LIKE CORN1\n",
      "  139: JOHN *SHOULD *CAR YESTERDAY BOOK                              JOHN BUY WHAT YESTERDAY BOOK\n",
      "  167: JOHN *LEAVE *LIKE *MARY MARY                                  JOHN IX SAY LOVE MARY\n",
      "   40: JOHN *LEAVE THINK MARY LOVE                                   JOHN IX THINK MARY LOVE\n",
      "   28: JOHN *LEAVE IX IX IX                                          JOHN LIKE IX IX IX\n",
      "  171: JOHN *IX BLAME                                                JOHN MARY BLAME\n",
      "   43: JOHN *SHOULD *NOT HOUSE                                       JOHN MUST BUY HOUSE\n",
      "  108: *JOHN ARRIVE                                                  WOMAN ARRIVE\n",
      "  174: *JOHN GROUP GIVE1 JANA *TOY1                                  PEOPLE GROUP GIVE1 JANA TOY\n",
      "  113: *JOHN CAR BLUE SUE *BUY1                                      IX CAR BLUE SUE BUY\n",
      "   50: *JOHN JOHN *GO *WHAT *<EOS>                                   FUTURE JOHN BUY CAR SHOULD\n",
      "  199: *JOHN CHOCOLATE WHO                                           LIKE CHOCOLATE WHO\n",
      "  158: *JOHN *MARY WHO                                               LOVE JOHN WHO\n",
      "   54: JOHN SHOULD NOT BUY HOUSE                                     JOHN SHOULD NOT BUY HOUSE\n",
      "  105: JOHN *LEAVE                                                   JOHN LEG\n",
      "  184: *JOHN BOY *GIVE1 TEACHER APPLE                                ALL BOY GIVE TEACHER APPLE\n",
      "   57: JOHN *LEAVE VISIT MARY                                        JOHN DECIDE VISIT MARY\n",
      "  122: JOHN *SHOULD BOOK                                             JOHN READ BOOK\n",
      "  189: JOHN *GIVE1 GIRL BOX                                          JOHN GIVE GIRL BOX\n",
      "  181: JOHN *GIVE1                                                   JOHN ARRIVE\n"
     ]
    }
   ],
   "source": [
    "showWER(test_dataset, model, [test_encoder_input, test_decoder_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Inference Model ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Extract the encoder part as a separate model so that the interim states\n",
    "    encoder_states can be extracted and manupulated before feeding into the decoder network\n",
    "    input: encoder_inputs as defined earlier\n",
    "    output: encoder_states\n",
    "\"\"\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "### prepare the initial state inputs for the decoder ###\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "### Note that we need also to input the decoder_inputs\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h, state_c] #again the states are extracted for futher loops\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "### inputs: states inputs(from encoder or previous steps of decoder)\n",
    "### outputs: softmax prediction as well as states for the next time step\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    beam_width = 3\n",
    "    \n",
    "    maxWordPerSentence = Ty\n",
    "    \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, noOfClasses))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, vocab2index['<SOS>']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_index_list = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token        \n",
    "        sampled_word_index = np.argmax(output_tokens[0, 0, :])\n",
    "        decoded_index_list.append(sampled_word_index)\n",
    "        \n",
    "        sampled_word = index2vocab[sampled_word_index]\n",
    "        #decoded_sentence = decoded_sentence + \" \" + sampled_word\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_word == '<EOS>' or\n",
    "           len(decoded_index_list) >= maxWordPerSentence):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, noOfClasses))\n",
    "        target_seq[0, 0, sampled_word_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateObj():\n",
    "    # Object to hold the Seq Candidates Data\n",
    "    def __init__(self, seq, state, logProb, normalizedProb, parentNode=None):\n",
    "        self.seq = seq\n",
    "        self.state = state\n",
    "        self.logProb = logProb\n",
    "        self.normalizedProb = normalizedProb\n",
    "        self.parentNode = parentNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDecoderOHTargetSeq(ind):\n",
    "    #create one hot target sequence (Y) based on index (int) provided\n",
    "    target_seq = np.zeros((1, 1, noOfClasses), dtype=np.int32)\n",
    "    target_seq[0, 0, ind] = 1 \n",
    "    return target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_sequence(input_seq, beam_width=3, printSentence=False):\n",
    "    \n",
    "    # Encode the input as state vectors. -> decoder\n",
    "    encoded_state_conditions = encoder_model.predict(input_seq) #states: list of state_h and state_c\n",
    "    \n",
    "    de_target_seq = createDecoderOHTargetSeq(vocab2index['<SOS>']) #use <SOS> to generate next stete\n",
    "    \n",
    "    nextWordProb, next_h, next_c = decoder_model.predict([de_target_seq] + encoded_state_conditions)\n",
    "    \n",
    "    nextWordProb = np.squeeze(nextWordProb)\n",
    "    \n",
    "    topProbIndex = np.argsort(nextWordProb)[::-1]\n",
    "\n",
    "    finalCandidateList = [] # for seq candidate which either reached <EOS> or Ty = 10\n",
    "    \n",
    "    beamList = [] # to hold current most promising top beam_width seq for further exploration\n",
    "\n",
    "    # create the initial beam list \n",
    "    for b in range(beam_width):\n",
    "        seq = copy.deepcopy([vocab2index['<SOS>']])\n",
    "        seq.append(topProbIndex[b])\n",
    "        logProb = np.log(nextWordProb[topProbIndex[b]])\n",
    "        noramlizedProb = logProb/1.0\n",
    "        c = CandidateObj(seq, [next_h, next_c], logProb, noramlizedProb)\n",
    "        beamList.append(c)\n",
    "    \n",
    "    assert(len(beamList) == beam_width)\n",
    "    \n",
    "    for t in range(1,Ty):\n",
    "        \n",
    "        ###  need an updated beamList (remove all unwanted candidates) before entering this loop ###\n",
    "        \n",
    "        #update cycle ends at the end of each time step\n",
    "        ram_candidateList = [] #temp list for storing all candidates sequence for later sorting\n",
    "        \n",
    "        for s in range(beam_width): \n",
    "            \n",
    "            nextBeam = copy.deepcopy(beamList[s])\n",
    "            nextInd = nextBeam.seq[-1]\n",
    "            nextState = nextBeam.state\n",
    "            de_target_seq = createDecoderOHTargetSeq(nextInd)\n",
    "            \n",
    "            nextWordProb, next_h, next_c = decoder_model.predict([de_target_seq] + nextState)\n",
    "            \n",
    "            nextWordProb = np.squeeze(nextWordProb)\n",
    "            \n",
    "            for ci in range(len(nextWordProb)):\n",
    "                newSeq = copy.deepcopy(nextBeam.seq)\n",
    "                newSeq.append(ci)\n",
    "                newState = [next_h, next_c]\n",
    "                newLogProb = nextBeam.logProb + np.log(nextWordProb[ci])\n",
    "                newParent = nextBeam #reference to previous object just in case\n",
    "                newNormalizedProb = newLogProb/(len(newSeq))\n",
    "                \n",
    "                new_c = CandidateObj(newSeq, newState, newLogProb, newNormalizedProb)\n",
    "                ram_candidateList.append(new_c)\n",
    "        \n",
    "        # time the sort the ram_candidateList\n",
    "        ram_candidateList = sorted(ram_candidateList, key=lambda x: x.normalizedProb, reverse=True)\n",
    "            \n",
    "        # time to update beamList and removed unwanted list\n",
    "        beamList = [] # reinitialize beamList\n",
    "        \n",
    "        for i in range(len(ram_candidateList)):\n",
    "            if len(beamList) < beam_width:\n",
    "                nextTopSeq = copy.deepcopy(ram_candidateList[i])\n",
    "                if nextTopSeq.seq[-1] == vocab2index['<EOS>']:\n",
    "                    finalCandidateList.append(copy.deepcopy(nextTopSeq))\n",
    "                else:\n",
    "                    beamList.append(nextTopSeq)\n",
    "    \n",
    "    # final sort!\n",
    "    finalCandidateList.extend(beamList)\n",
    "    finalCandidateList.sort(key=lambda x: x.normalizedProb, reverse=True)\n",
    "    \n",
    "    return finalCandidateList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Index: 3\n",
      "['JOHN', 'CAN', 'BUY', 'HOUSE', '<EOS>']\n",
      "['JOHN', 'CAN', 'BUY', 'HOUSE', '<EOS>']\n",
      "['JOHN', 'CAN', 'GO', 'CAN', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "Sample Index: 18\n",
      "['JOHN', 'LIKE', 'IX', 'IX', 'IX', '<EOS>']\n",
      "['JOHN', 'LIKE', 'IX', 'IX', 'IX', '<EOS>']\n",
      "['JOHN', 'LIKE', 'IX', 'IX', 'IX', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "Sample Index: 15\n",
      "['JOHN', 'LEAVE', 'IX', '<EOS>']\n",
      "['JOHN', 'WILL', 'VISIT', 'MARY', '<EOS>']\n",
      "['JOHN', 'WILL', 'VISIT', 'MARY', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "Sample Index: 21\n",
      "['JOHN', 'BUY', 'CAR', 'FUTURE', 'NOT', '<EOS>']\n",
      "['JOHN', 'LIKE', 'IX', 'IX', 'IX', '<EOS>']\n",
      "['JOHN', 'BUY', 'WHAT', 'YESTERDAY', 'BOOK', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "Sample Index: 5\n",
      "['JOHN', 'LEAVE', 'IX', '<EOS>']\n",
      "['JOHN', 'LEAVE', 'IX', '<EOS>']\n",
      "['JOHN', 'NOT', 'VISIT', 'MARY', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in [np.random.randint(len(test_encoder_input)) for t in range(5)]:\n",
    "    print(\"Sample Index: {}\".format(s))\n",
    "    decoded_index_list = decode_sequence(test_encoder_input[s:s+1,:,:])\n",
    "    finalCandidateList = beam_search_sequence(test_encoder_input[s:s+1,:,:], beam_width=3)\n",
    "\n",
    "    test_truth = np.argmax(test_decoder_target[s,:,:], axis=-1)\n",
    "\n",
    "    print(([index2vocab[t] for t in decoded_index_list]))\n",
    "    print(([index2vocab[t] for t in finalCandidateList[0].seq if t != vocab2index['<SOS>']]))\n",
    "    print([index2vocab[t] for t in test_truth], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_index = [s[0] for s in sorted(test_dataset.sentences_index.items())]\n",
    "#original_index = [s[0] for s in test_dataset.sentences_index.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38, 9, 28, 15, 20]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
